---
title: "Understanding Word Embedding"
author: "Arjun Paudel"
date: "6/7/2021"
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidytext)
library(textdata)
library(widyr)
```

```{r}
dt <- tibble(id = c(1,2,1,2),
             text = c("This is a good dog",
                      "Who is a good boy",
                      "Boy, it sure is hot today, huh?",
                      "This is a hot summer month")
             )
dt <- dt %>% arrange(id)
dt
```

```{r}
tidy_dt <- dt %>% 
  unnest_tokens(word, text)
tidy_dt
```

```{r}
tidy_ngram_dt <- dt %>% 
  unnest_tokens(words, text, token = "ngrams", n = 2, collapse = "id") %>% 
  mutate(.ngramID = row_number()) %>% 
  unnest_tokens(word, words) %>% 
  unite(.ngramID, id, .ngramID)

tidy_pmi <- tidy_ngram_dt %>% 
  pairwise_pmi(item = word, feature = .ngramID, sort = TRUE)
tidy_pmi
```

> Notice the use of `collapse = "id"`
>
> Without this, the bigram tokenizer will stop at the end of each row and will not crossover to next row.
>
> With `collapse = "id"` it will cross over to next row with same id and treat last word of previous row and first word of next row together.
>
> In our case, row1 and row3 have same ***id***, so we can think of this as one single long sentence that we just chose to represent in two rows. `collapse = "id"` will treat it such.
>
> Sometimes we read a big text file, certain number of lines at a time. So all the text of same document can end up in different rows. They will share the same document id but not row number. Using `collapse = "document_id"` will treat all those different rows as part of same document.

Implementation from [smltar](https://smltar.com/embeddings.html)

```{r}

nested_words <- tidy_dt %>%
  nest(words = c(word))

nested_words


slide_windows <- function(tbl, window_size) {
  skipgrams <- slider::slide(
    tbl, 
    ~.x, 
    .after = window_size - 1, 
    .step = 1, 
    .complete = TRUE
  )
  
  safe_mutate <- safely(mutate)
  
  out <- map2(skipgrams,
              1:length(skipgrams),
              ~ safe_mutate(.x, window_id = .y))

  out %>%
    transpose() %>%
    pluck("result") %>%
    compact() %>%
    bind_rows()
}


tidy_pmi2 <- nested_words %>%
  mutate(words = map(words, slide_windows, 2L)) %>%
  unnest(words) %>%
  unite(window_id, id, window_id) %>%
  pairwise_pmi(word, window_id, sort = TRUE)

tidy_pmi2

```

PMI calculated by both methods is identical.

```{r}
identical(tidy_pmi, tidy_pmi2)
```

### Represent words as numeric vectors

Create 5 dimensional vector using `widely_svd()` from **widyr** package

```{r}
set.seed(13)
tidy_word_vectors <- tidy_pmi %>% 
  widely_svd(
    item1, item2, pmi,
    nv = 5, maxit = 10000
  )
```

Using `irlba()` from **irlba** library

```{r}
pmi_matrix <- tidy_pmi %>% 
  cast_sparse(item1, item2, pmi)

class(pmi_matrix)
library(irlba)

set.seed(13)
pmi_svd <- irlba(pmi_matrix, nv=5, maxit = 10000)
pmi_svd

word_vectors <- pmi_svd$u
rownames(word_vectors) <- rownames(pmi_matrix)

```

Values are almost identical except for third dimension. Not sure if this is rounding error or if these two libraries differ how they implement SVD.  There are also some sign inconsistencies.

> Actually looking at source code of `widely_svd()`, it calls `irba()`. Not really sure what is causing the discrepancy.

> Realized that the inconistencies were due to random nature of the process. Both svd processes resulted in identical result after setting same seed before function calls.

```{r}
word_vectors
(tidy_word_vectors %>% cast_sparse(item1, dimension, value))
```

#### Similarity

Similarity between vector representation of words can be found using cosine similarity.        
$sim(x,y) = \frac{x.y}{||x||.||y||}$

$x = (5, 0, 3, 0, 2, 0, 0, 2, 0, 0)$ and  $y = (3, 0, 2, 0, 1, 1, 0, 1, 0, 1)$     
$x.y = x^{t}.y = 5*3+0*0+3*2+0*0+2*1+0*1+0*0+0*1 = 25$     
$||x|| = \sqrt{5^2+0^2+3^2+0^2+2^2+0^2+0^2+2^2+0^2+0^2} = 6.48$     
$||y|| = \sqrt{3^2+0^2+2^2+0^2+1^2+1^2+0^2+1^2+0^2+1^2} = 4.12$        
$sim(x,y) = \frac{25}{6.48*4.12} = 0.94$    


Some matrix multiplication quirks to understand.

Let's create a 2x2 matrix.
```{r}
a <- matrix(c(1,2,1,2), nrow = 2, byrow = TRUE)
a
```

If we slice one row or one column, the result is just a vector not a matrix.
```{r}
a[1,]
a[,1]
```

Matrix have dimensions but the dimension of a vector is `NULL`
```{r}
a %>% dim()
a[1,] %>% dim()
a[,1] %>% dim()
```

Since the dimension of an vector is NULL it can act as a row vector or column vector.    
In this case it acts as a 1x2 row vector and so can be multiplied by a 2x2 matrix.
$a^*_{1\times2}*a_{2\times2}$
```{r}
a[1,]%*%a
```

Here it acts as 2x1 column vector and can multiply a.    
$a_{2\times2}*a^*_{2\times1}$
```{r}
a%*%a[1,]
```

Outcome of both above operations result in a matrix of appropriate dimensions.

```{r}
nearest_neighbors <- function(df, token) {
  df %>%
    widely(
      ~ {
        y <- (. %*% (.[token, ]))[,1]
        res <- y / 
          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))
      matrix(res, ncol = 1, dimnames = list(x = names(res)))
      },
      sort = TRUE
    )(item1, dimension, value) %>% 
  select(-item2)
}
```

Implementation from the book
```{r}
nearest_neighbors2 <- function(df, token) {
  df %>%
    widely(
      ~ {
        y <- .[rep(token, nrow(.)), ]
        res <- rowSums(. * y) / 
          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))

        matrix(res, ncol = 1, dimnames = list(x = names(res)))
        },
      sort = TRUE
    )(item1, dimension, value) %>%
    select(-item2)
}
```

Identical results
```{r}
tidy_word_vectors %>% nearest_neighbors2("today")
tidy_word_vectors %>% nearest_neighbors("today")
```

#### Word embedding

Now we have documents made up of multiple words and we know the vector representation of those words. So how do we go about representing the documents in vector form.    
One common approach is to aggregate the word vectors of all the words that make up the document. We could sum all those word vectors of a document or average them or take the min/max across each dimension.    

We need a matrix of *document_id*, *words* and the count of how many times that word appears in that document.

Document-term matrix
```{r}
tidy_dt %>% head()
doc_term_matrix <- tidy_dt %>% 
  count(id, word) %>% 
  cast_sparse(id, word, n)
```

Word embedding matrix
```{r}
tidy_word_vectors %>% head()
embedding_matrix <- tidy_word_vectors %>%
  cast_sparse(item1, dimension, value)
embedding_matrix
```


```{r}
doc_term_matrix %*% embedding_matrix 
```

```{r}
test_dtm <- matrix(c(1,2,0,2,0,1), nrow = 2)
dimnames(test_dtm) <- list(c(1,2), c("the", "good", "boy"))
test_dtm
test_embed <- matrix(c(.2,.4,.1,1,2,3,.5,.25,.4, .02,.15,.8), nrow = 3)
dimnames(test_embed) <- list(c("the", "good", "boy"), c("d1", "d2", "d3", "d4"))
test_embed

doc_matrix <- test_dtm %*% test_embed
doc_matrix
```

We can replicate this using simple count, sum and multiplication in tidy format.

```{r}
tidy_embed<-test_embed %>% as_tibble(rownames = "word") %>% 
  pivot_longer(!word, names_to = "dimension", values_to = "value")

tidy_dtm <- tibble(word = rep(c("the", "good", "boy"), times = 2),
                   id = rep(c(1,2), each = 3,),
                   n = c(1,0,0,2,2,1)
)

tidy_doc_matrix <- tidy_dtm %>% left_join(tidy_embed, by = "word") %>% 
  mutate(value = n*value) %>% 
  pivot_wider(names_from = dimension, values_from = value,values_fill = 0) %>% 
  group_by(id) %>% 
  summarise(across (starts_with("d"), sum))

```

Both results are identical

```{r}
doc_matrix
tidy_doc_matrix
```

